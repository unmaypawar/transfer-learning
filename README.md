# transfer-learning

## Description

<p>This project aims to compare the performance of transfer learning architectures in the task of image classification. Transfer learning is a technique widely used in deep learning, leveraging pre-trained models to achieve better performance on new tasks with limited labeled data. In this project, main focus is on comparing the performance of Convolutional Neural Network (CNN) models with Multilayer Perceptrons (MLPs) against state-of-the-art architectures including EfficientNetB0, ResNet50 and VGG16.</p>

<p>It uses image dataset "ML-ready Dataset for Identification of Frost in Martian HiRISE Images" from NASA's Jet Propulsion Laboratory (JPL). It preprocess, augments and trains the data and evaluates the models' performance using standard evaluation metrics such as accuracy, precision, recall, and F1-score. By comparing the performance of different transfer learning architectures, this study aims to provide insights into the effectiveness of various deep learning models for image classification tasks. The findings can guide researchers and practitioners in selecting the most suitable architecture based on the specific requirements of their applications, balancing between accuracy, computational cost, and resource constraints.</p>

## Installation Instructions

```
conda create --name transfer_learning --file requirements.txt
```

## Usage Instructions

## Support Information

Please raise an issue or a pull request.